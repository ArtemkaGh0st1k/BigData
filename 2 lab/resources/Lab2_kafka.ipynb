{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "    <center>МИНИСТЕРСТВО НАУКИ И ВЫСШЕГО ОБРАЗОВАНИЯ</center>\n",
    "    <center>федеральное государственное автономное образовательное учреждение высшего образования </center> <center>«Самарский национальный исследовательский университет имени академика С.П. Королева»</center>\n",
    "    <center>(Самарский университет)</center> </br>\n",
    "\n",
    "<br/>\n",
    "\n",
    "<br>\n",
    "<center>Институт \t     информатики и кибернетики</center>                                                   \t  \n",
    "<center>Кафедра \t     технической кибернетики</center>                                                              \t\n",
    "</br>\n",
    "<br/>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br>\n",
    "<center>ОТЧЕТ</center>\n",
    "<center>по лабораторной работе №2</center>\n",
    "\n",
    "<center>«Обработка данных с использование Kafka»</center>\n",
    "<br/>\n",
    "<center>по дисциплине <strong>«Большие данные»</strong></center>\n",
    "<br/>\n",
    "<center></center>\n",
    "</br>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "<p style=\"text-align:right;\">Выполнил: Фамилия И.О.\n",
    "<br>613х-010402D\n",
    "<br>    \n",
    "<br>Преподаватель: Попов С.Б.\n",
    "</p>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "    <br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<center>Самара 2025</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Экспорт необходимых модулей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaProducer\n",
    "from kafka import KafkaConsumer\n",
    "from kafka.errors import KafkaError\n",
    "from kafka.structs import TopicPartition\n",
    "\n",
    "from kafka.admin import KafkaAdminClient, NewTopic, NewPartitions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Определение списка серверов kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_servers = 'localhost:9092'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Реализация схемы с одним обработчиком (one consumer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создание топика для схемы *one consumer*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "admin_client = KafkaAdminClient(bootstrap_servers=bootstrap_servers)\n",
    "\n",
    "topic1 = 'rides1-events'\n",
    "\n",
    "topic_list = []\n",
    "topic_list.append(NewTopic(name=topic1, num_partitions=1, replication_factor=1))\n",
    "admin_client.create_topics(new_topics=topic_list, validate_only=False)\n",
    "\n",
    "print(admin_client.list_topics())\n",
    "\n",
    "admin_client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Реализация источника данных (producer)\n",
    "\n",
    "1. Создаём экземпляр класса KafkaProducer (не забываем определить сериализаторы для key- и value-составляющих в сообщении)\n",
    "2. Подключаем доступ на чтение из файла *riders.csv*\n",
    "3. Читаем и пропускаем первую строку-заголовок\n",
    "4. В цикле считываем строки из csv-файла и отправлем их в топик\n",
    "5. Завершаем работу объекта KafkaProducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "producer = KafkaProducer(bootstrap_servers=[bootstrap_servers],\n",
    "                        key_serializer= lambda key: key.encode('utf-8'),\n",
    "                        value_serializer= lambda value: value.encode('utf-8'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "producer.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Реализация обработчика данных (consumer)\n",
    "\n",
    "1. Создаём экземпляр класса KafkaConsumer (не забываем в параметрах определить параметр *consumer_timeout_ms* и десериализаторы для key- и value-составляющих в сообщении)\n",
    "2. Создаём массивы для накопления значений trip_count, passenger_count, trip_distance, total_amount с нулевыми значениями и соответствующим типом данных\n",
    "3. В цикле получения сообщений объекта KafkaConsumer:\n",
    "   * разделяем получаемую value-строку на отдельные элементы,\n",
    "   * выделяем значение VendorID или используем key, если источник передаёт его в сообщении,\n",
    "   * обновляем значения в массивах-накопителях, используя (VendorID - 1) как индекс соответствующего массива \n",
    "4. Распечатываем отдельно для каждого перевозчика:\n",
    "   * количество поездок(trip_count),\n",
    "   * число перевезённых пассажиров(passenger_count),\n",
    "   * расстояние поездок(trip_distance)\n",
    "   * сумму оплаты(total_amount)\n",
    "5. Завершаем работу объекта KafkaProducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer = KafkaConsumer(topic1,\n",
    "                         auto_offset_reset='earliest',\n",
    "                         consumer_timeout_ms=2000,\n",
    "                         key_deserializer= lambda key: int(key.decode('utf-8')),\n",
    "                         value_deserializer= lambda value: value.decode('utf-8'),\n",
    "                         bootstrap_servers=[bootstrap_servers])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Реализация схемы с двумя обработчиками (two consumers launched in a group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создание топика для схемы *two consumer*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!! Не забываем указать количество разделов с помощью параметра *num_partitions=2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Реализация источника данных (producer)\n",
    "\n",
    "1. Создаём экземпляр класса KafkaProducer (не забываем определить сериализаторы для key- и value-составляющих в сообщении)\n",
    "2. Подключаем доступ на чтение из файла *riders.csv*\n",
    "3. Читаем и пропускаем первую строку-заголовок\n",
    "4. В цикле считываем строки из csv-файла:\n",
    "    * преобразуем строку в список элементов (используем метод split(','))\n",
    "    * выделяем значение VendorID\n",
    "    * отправлем сообщение в топик с key=*VendorID* и value=*cтрока файла*\n",
    "6. Завершаем работу объекта KafkaProducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Полезные утилиты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Просмотр списка топиков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka.errors import KafkaError\n",
    "from kafka.structs import TopicPartition\n",
    "from kafka.admin import KafkaAdminClient, NewTopic, NewPartitions\n",
    "\n",
    "bootstrap_servers = 'localhost:9092'\n",
    "\n",
    "admin_client = KafkaAdminClient(bootstrap_servers=bootstrap_servers)\n",
    "\n",
    "print(admin_client.list_topics())\n",
    "\n",
    "admin_client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Удаление топика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka.errors import KafkaError\n",
    "from kafka.structs import TopicPartition\n",
    "from kafka.admin import KafkaAdminClient, NewTopic, NewPartitions\n",
    "\n",
    "bootstrap_servers = 'localhost:9092'\n",
    "\n",
    "# ниже введите имя топика из списка, распечатанного предыдущей ячейкой\n",
    "topic_for_del = '__consumer_offsets'\n",
    "\n",
    "admin_client = KafkaAdminClient(bootstrap_servers=bootstrap_servers)\n",
    "admin_client.delete_topics([topic_for_del])\n",
    "\n",
    "print(admin_client.list_topics())\n",
    "\n",
    "admin_client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Просмотр списка групп"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka.errors import KafkaError\n",
    "from kafka.structs import TopicPartition\n",
    "from kafka.admin import KafkaAdminClient, NewTopic, NewPartitions\n",
    "\n",
    "bootstrap_servers = 'localhost:9092'\n",
    "\n",
    "admin_client = KafkaAdminClient(bootstrap_servers=bootstrap_servers)\n",
    "\n",
    "print(admin_client.list_consumer_groups())\n",
    "\n",
    "admin_client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Просмотр описания заданной группы (в данном случае – *rides2*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka.errors import KafkaError\n",
    "from kafka.structs import TopicPartition\n",
    "from kafka.admin import KafkaAdminClient, NewTopic, NewPartitions\n",
    "\n",
    "bootstrap_servers = 'localhost:9092'\n",
    "\n",
    "admin_client = KafkaAdminClient(bootstrap_servers=bootstrap_servers)\n",
    "\n",
    "print(admin_client.describe_consumer_groups(group_ids=['rides2']))\n",
    "\n",
    "admin_client.close()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
