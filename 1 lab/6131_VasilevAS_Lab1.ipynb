{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4840180e",
   "metadata": {},
   "source": [
    "<br>\n",
    "    <center>МИНИСТЕРСТВО НАУКИ И ВЫСШЕГО ОБРАЗОВАНИЯ</center>\n",
    "    <center>федеральное государственное автономное образовательное учреждение высшего образования </center> <center>«Самарский национальный исследовательский университет имени академика С.П. Королева»</center>\n",
    "    <center>(Самарский университет)</center> </br>\n",
    "\n",
    "<br/>\n",
    "\n",
    "<br>\n",
    "<center>Институт \t     информатики и кибернетики</center>                                                   \t  \n",
    "<center>Кафедра \t     технической кибернетики</center>                                                              \t\n",
    "</br>\n",
    "<br/>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br>\n",
    "<center>ОТЧЕТ</center>\n",
    "<center>по лабораторной работе №1</center>\n",
    "\n",
    "<center>«Введение в MapReduce модель на Python»</center>\n",
    "<br/>\n",
    "<center>по дисциплине <strong>«Большие данные»</strong></center>\n",
    "<br/>\n",
    "<center></center>\n",
    "</br>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "<p style=\"text-align:right;\">Выполнил: Васильев А.С.\n",
    "<br>6131-010402D\n",
    "<br>    \n",
    "<br>Преподаватель: Попов С.Б.\n",
    "</p>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "    <br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<center>Самара 2025</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1022eb3",
   "metadata": {},
   "source": [
    "# **Модель MapReduce**\n",
    "Функция MapReduce имитирует работу фреймворка MapReduce: подготовка и форматирование исходных данных в виде набора пар ключ-значение (key-value) для последующего вызова функции MAP, вызов функции MAP, группировка промежуточных результатов работы функции MAP по ключу и формирование массива значений для каждого ключа, вызов функции REDUCE.\n",
    "\n",
    "Пользователь для решения своей задачи реализует функции RECORDREADER, MAP, REDUCE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6671c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(nested_iterable):\n",
    "  for iterable in nested_iterable:\n",
    "    for element in iterable:\n",
    "      yield element\n",
    "\n",
    "def groupbykey(iterable):\n",
    "  t = {}\n",
    "  for (k2, v2) in iterable:\n",
    "    t[k2] = t.get(k2, []) + [v2]\n",
    "  return t.items()\n",
    "\n",
    "def MapReduce(RECORDREADER, MAP, REDUCE):\n",
    "  return flatten(map(lambda x: REDUCE(*x), groupbykey(flatten(map(lambda x: MAP(*x), RECORDREADER())))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17c6b69",
   "metadata": {},
   "source": [
    "## Режимы данных:\n",
    "- `embedded` — использовать встроенные в ноутбук данные (аннотации и граф).\n",
    "- `docx` — распарсить `/mnt/data/Lab1_данные.docx` напрямую без внешних библиотек.\n",
    "\n",
    "Переключается константой `DATA_MODE` ниже.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ce58ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD -->  c:\\Users\\Артем\\Desktop\\Study\\1 sem\\BigData\\1 lab\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_MODE = \"docx\"\n",
    "LINE_MODE = False\n",
    "DOCX_PATH = \"Lab1_данные.docx\"\n",
    "\n",
    "print(\"CWD --> \", Path.cwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972ed534",
   "metadata": {},
   "source": [
    "# Обработка документа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9aef12e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "\n",
    "\n",
    "def read_docx_file(path) -> list[str]:\n",
    "    \"\"\" Чтение .docx файла и возврат как список строк \"\"\"\n",
    "\n",
    "    # открытие файла с помощью класса ZipFile и последующее чтение XML документа\n",
    "    with ZipFile(path) as zf:\n",
    "        xml = zf.read(\"word/document.xml\")\n",
    "\n",
    "    ns = {\"w\" : \"http://schemas.openxmlformats.org/wordprocessingml/2006/main\"}     # пространство имен WordprocessingML\n",
    "    root = ET.fromstring(xml)       # парсим xml и собираем список параграфов\n",
    "\n",
    "    paras = []\n",
    "    for p in root.findall(\".//w:p\", ns):\n",
    "        texts = [t.text for t in p.findall(\".//w:t\", ns) if t.text]     # внутри абзаца собираем все текстовые узлы <w:t>\n",
    "        paras.append(\"\".join(texts) if texts else \"\")       # склевиаем в одну строку \n",
    "\n",
    "    return [re.sub(r\"\\s+\", \" \", t).strip() for t in paras]      # нормализация пробелов в каждом параграфе - сжимаем подряд и обрезаем края"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "193a850c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_lab_data_from_docx(path):\n",
    "\n",
    "    paras = read_docx_file(path)\n",
    "    text = \"\\n\".join(paras)\n",
    "\n",
    "    # -------- Извлечение документов (аннотаций) -------- #\n",
    "\n",
    "    docs, current = [], []\n",
    "    in_docs = False\n",
    "\n",
    "    for line in paras:\n",
    "\n",
    "        # заголовок раздела аннотации \n",
    "        if re.search(r\"^\\s*Аннотац\", line, re.IGNORECASE):\n",
    "\n",
    "            # если накапливался предю документ - сохраняем\n",
    "            if current:\n",
    "                docs.append(\" \".join(current).strip())\n",
    "                current = []\n",
    "            \n",
    "            in_docs = True\n",
    "            continue\n",
    "\n",
    "        if in_docs:\n",
    "            \n",
    "            # дошли до раздела со списком смежности - значит, аннотация закончилась\n",
    "            if re.search(r\"Список\\s+смежности\", line, re.IGNORECASE):\n",
    "                break\n",
    "            \n",
    "            # копим непустые строки текущего документа\n",
    "            if line.strip():\n",
    "                current.append(line.strip())\n",
    "\n",
    "    # финальный \"хвост\" документа, если остался    \n",
    "    if current:\n",
    "        docs.append(\" \".join(current).strip())\n",
    "\n",
    "\n",
    "    # -------- Извлечение списка смежности -------- #\n",
    "\n",
    "    adj = {}\n",
    "    in_adj = False\n",
    "\n",
    "    for line in paras:\n",
    "\n",
    "        # начало раздела \"Список смежности\"\n",
    "        if re.search(r\"Список\\s+смежности\", line, re.IGNORECASE):\n",
    "            in_adj = True\n",
    "            continue\n",
    "\n",
    "        if in_adj:\n",
    "\n",
    "            # пропускаем строки без цифр\n",
    "            if not re.search(r\"\\d\", line):\n",
    "                continue\n",
    "            \n",
    "            # достаем все числа из строки: первое - вершина, остальное соседи\n",
    "            nums = list(map(int, re.findall(r\"\\d+\", line)))\n",
    "            if nums:\n",
    "                u, *nrbs = nums\n",
    "                adj[u] = nrbs\n",
    "\n",
    "\n",
    "    return (docs, adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4602a3ea",
   "metadata": {},
   "source": [
    "# Проверка работоспособности "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afa35c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] DOCX parsing failed: [Errno 2] No such file or directory: 'Lab1_данные.docx' \n",
      "Fallback to embedded.\n",
      "Data mode: docx. Documents: 8; Nodes: 20\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "adj = {}\n",
    "if DATA_MODE == \"docx\":\n",
    "    try:\n",
    "        # Пытаемся распарсить DOCX: получаем корпус аннотаций и список смежности\n",
    "        documents, adj = parse_lab_data_from_docx(DOCX_PATH)\n",
    "\n",
    "        # Если парсер вернул пустые данные — мягко откатываемся на встроенные (embedded)\n",
    "        if not documents or not adj:\n",
    "            print(\"[WARN] DOCX parsing incomplete — fallback to embedded.\")\n",
    "\n",
    "            # Встроенный корпус документов (embedded), чтобы ноутбук был самодостаточным\n",
    "            documents = [\"Streaming data is the data from sensors as well as other real-time surveillance systems. Distributed stream processing systems are the software that manages such data. Such frameworks have to deliver outcomes on the go instantly. They are susceptible to delay and malfunction or system failures. The system must be tolerant of faults and always accessible. Many variables, such as improved network arrival rates, node failures, and so on, disrupt the system's reliability. Some operators need to be relocated online from one physical resource to another to manage or reimburse a slow or failing node. In this study, we propose a co-location based systematic migration heuristic for live operator migration between physical resources using a migration map revised with costs for each migration. The suggested method evaluates continuous operator performance patterns and makes online scheduling decisions based on the same. The decisions include migrating operators during a node failure or straggling.\", \"Distributed stream processing engines are designed with a focus on scalability to process big data volumes in a continuous manner. We present the Theodolite method for benchmarking the scalability of distributed stream processing engines. Core of this method is the definition of use cases that microservices implementing stream processing have to fulfill. For each use case, our method identifies relevant workload dimensions that might affect the scalability of a use case. We propose to design one benchmark per use case and relevant workload dimension. We present a general benchmarking framework, which can be applied to execute the individual benchmarks for a given use case and workload dimension. Our framework executes an implementation of the use case's dataflow architecture for different workloads of the given dimension and various numbers of processing instances. This way, it identifies how resources demand evolves with increasing workloads. Within the scope of this paper, we present 4 identified use cases, derived from processing Industrial Internet of Things data, and 7 corresponding workload dimensions. We provide implementations of 4 benchmarks with Kafka Streams and Apache Flink as well as an implementation of our benchmarking framework to execute scalability benchmarks in cloud environments. We use both for evaluating the Theodolite method and for benchmarking Kafka Streams' and Flink's scalability for different deployment options.\", \"Batch and stream processing are separately and efficiently applied in many applications. However, some newer data-driven applications such as the Internet of Things and cloud computing call for hybrid processing approaches in order to handle the speed and accuracy required for processing such complex data. In this paper, we propose a Hybrid Distributed Batch-Stream (HDBS) architecture for anomaly detection in real-time data. The hybrid architecture, while benefiting from the accuracy provided by batch processing, also enjoys the speed and real-time features of stream processing. In the proposed architecture, our focus is on the algorithmic aspects of hybrid processing including the interaction models between batch and stream processing units, the characteristics of batch and stream machine learning algorithms and the principles of merging the results of different processing units. The driving idea of such combination is that the results of batch and stream processing units are complementary with each other, as one of them constructs accurate models based on previous data, and the other one is capable of processing new stream data in real-time. Furthermore, we propose a generalized version of the HDBS with respect to its algorithms and communication policy levels. In the generalized HDBS architecture, we address the various aspects of the interaction between the batch and stream processing units, and the merging operations to produce the final results. the evaluations of the proposed architecture using various criteria (accuracy, space complexity, and time complexity) demonstrate that the accuracy of the proposed method is higher than the accuracy of the batch processing methods, its time complexity is also similar to one of the stream processing methods and much less than the batch processing methods, which makes our proposed architecture an efficient and practical solution for real-time anomaly detection.\", \"There have been increasing demands for real time processing of the ever-growing data. In order to meet this requirement and ensure the reliable processing of streaming data, a variety of distributed stream processing architectures and platforms have been developed, which handles the fundamental task of allocating processing tasks to the currently available physical resources and routing streaming data between these resources. However, many stream processing systems lack an intelligent scheduling mechanism, in which their default schedulers allocate tasks without taking resource demands and availability, or the transfer latency between resources into consideration. Besides, stream processing has a strict request for latency. Thus it is important to give latency guarantee for distributed stream processing. In this paper, we propose two new algorithms for stream processing with latency guarantee, both the algorithms consider transfer latency and resource demand in task allocation. Both algorithms can guarantee latency constraints. Algorithm AHA reduces more than 21.3% and 58.9% resources compared with the greedy and the round-robin algorithms, and algorithm PHA further improves the resource utilization to 32.1% and 73.2%.\", \"In the era of Big Data, typical architecture of distributed real-time stream processing systems is the combination of Flume, Kafka, and Storm. As a kind of distributed message system, Kafka has the characteristics of horizontal scalability and high throughput, which is manly deployed in many areas in order to address the problem of speed mismatch between message producers and consumers. When using Kafka, we need to quickly receive data sent by producers. In addition, we need to send data to consumers quickly. Therefore, the performance of Kafka is of critical importance to the performance of the whole stream processing system. In this paper, we propose the improved design of real-time stream processing systems, and focus on improving the Kafka’s data loading process. We use Kafka cat to transfer data from the source to Kafka topic directly, which can reduce the network transmission. We also utilize the memory file system to accelerate the process of data loading, which can address the bottleneck and performance problems caused by disk I/O. Extensive experiments are conducted to evaluate the performance, which show the superiority of our improved design.\", \"In this paper, nearly 40 commonly used deep neural network(DNN) models are selected, and their cross-platform and cross-inference frameworks are deeply analysed. The main metrics of accuracy, the total number of model parameters, the computational complexity, the accuracy density, the inference time, the memory consumption and other related parameters are used to measure their performance. The heterogeneous computing experiment is implemented on both the Google Colab cloud computing platform and the Jetson Nano embedded edge computing platform. The obtained performance is compared with that of two previous computing platforms: a workstation equipped with an NVIDIA Titan X Pascal and an embedded system based on an NVIDIA Jetson TX1 board. In addition, on the Jetson Nano embedded edge computing platform, different inference frameworks are investigated to evaluate the inference efficiency of the DNN models. Regression models are established to characterize the variation in the computing performance of different DNN classification algorithms so that the inference results of unknown models can be estimated. ANOVA methods are proposed to quantify the differences between models. The experimental results have important guiding significance for the better selection, deployment and application of DNN models in practice. Codes are available at this https URL https://github.com/Foreverzfy/Model-Test.\", \"Unmanned Aerial Vehicles (UAVs), which can operate autonomously in dynamic and complex environments, are becoming increasingly common. Deep learning techniques for motion control have recently taken a major qualitative step since vision-based inference tasks can be executed directly on edge. The goal is to fully integrate the machine learning (ML) element into small UAVs. However, given the limited payload capacity and energy available on small UAVs, integrating computing resources sufficient to host ML and vehicle control functions is still challenging. This paper presents a modular and generic system that can control the UAV by evaluating vision-based ML tasks directly inside the resource-constrained UAV. Two different vision-based navigation configurations were tested and demonstrated. The first configuration implements an autonomous landing site detection system, tested with two models based on LeNet-5 and MobileNetV2, respectively. This allows the UAV to change its planned path accordingly and approach the target to land. Moreover, a model for people detection based on a custom MobileNetV2 network was evaluated in the second configuration. Finally, the execution time and power consumption were measured and compared with a cloud computing approach. The results show the ability of the developed system to dynamically react to the environment to provide the necessary maneuver after detecting the target exploiting only the constrained computational resources of the UAV controller. Furthermore, we demonstrated that moving to the edge, instead of using cloud computing inference, decreases the energy requirement of the system without reducing the quality of service.\", \"With the continuous development of Internet of Things (IoT) and the overwhelming explosion of Big Data, edge computing serves as an efficient computing mode for time stringent data processing, which can bypass the constraints of network bandwidth and delay, and has been one of the foundation of interconnected applications. Although edge computing has gradually become one of bridges between cloud computing centers and mobile terminals, the literature still lacks a thorough review on the recent advances in edge computing platforms. In this paper, we firstly introduce the definition of edge computing and advantages of edge computing platform. And then, we summarize the key technologies of constructing an edge computing platform, and propose a general framework for edge computing platform. The role of distributed storage management systems in building edge computing platform is elaborated in detail. Furthermore, we give some applications to illustrate how to use third-party edge computing platforms to build specific applications. Finally, we briefly outline current open issues of edge computing platform based on our literature survey.\"]\n",
    "            \n",
    "            # Встроенный список смежности (обратите внимание: ключи-строки; если нужно int — можно привести позже)\n",
    "            adj = {\"0\": [1, 3], \"1\": [0, 2, 4], \"2\": [1, 3, 5, 6], \"3\": [0, 2, 8], \"4\": [1, 10, 11], \"5\": [2, 8, 10], \"6\": [2, 7], \"7\": [6, 12], \"8\": [3, 5, 7, 9], \"9\": [8, 10], \"10\": [4, 5, 9, 11, 16], \"11\": [4, 10, 13], \"12\": [7, 14], \"13\": [11, 14], \"14\": [12, 13, 15], \"15\": [14, 16], \"16\": [10, 15, 17], \"17\": [16, 18], \"18\": [17, 19], \"19\": [18]}\n",
    "    except Exception as e:\n",
    "\n",
    "        # Любая ошибка парсинга DOCX — не фейлим ноутбук, а мягко используем embedded\n",
    "        print(\"[WARN] DOCX parsing failed:\", e, \"\\nFallback to embedded.\")\n",
    "\n",
    "        documents = [\"Streaming data is the data from sensors as well as other real-time surveillance systems. Distributed stream processing systems are the software that manages such data. Such frameworks have to deliver outcomes on the go instantly. They are susceptible to delay and malfunction or system failures. The system must be tolerant of faults and always accessible. Many variables, such as improved network arrival rates, node failures, and so on, disrupt the system's reliability. Some operators need to be relocated online from one physical resource to another to manage or reimburse a slow or failing node. In this study, we propose a co-location based systematic migration heuristic for live operator migration between physical resources using a migration map revised with costs for each migration. The suggested method evaluates continuous operator performance patterns and makes online scheduling decisions based on the same. The decisions include migrating operators during a node failure or straggling.\", \"Distributed stream processing engines are designed with a focus on scalability to process big data volumes in a continuous manner. We present the Theodolite method for benchmarking the scalability of distributed stream processing engines. Core of this method is the definition of use cases that microservices implementing stream processing have to fulfill. For each use case, our method identifies relevant workload dimensions that might affect the scalability of a use case. We propose to design one benchmark per use case and relevant workload dimension. We present a general benchmarking framework, which can be applied to execute the individual benchmarks for a given use case and workload dimension. Our framework executes an implementation of the use case's dataflow architecture for different workloads of the given dimension and various numbers of processing instances. This way, it identifies how resources demand evolves with increasing workloads. Within the scope of this paper, we present 4 identified use cases, derived from processing Industrial Internet of Things data, and 7 corresponding workload dimensions. We provide implementations of 4 benchmarks with Kafka Streams and Apache Flink as well as an implementation of our benchmarking framework to execute scalability benchmarks in cloud environments. We use both for evaluating the Theodolite method and for benchmarking Kafka Streams' and Flink's scalability for different deployment options.\", \"Batch and stream processing are separately and efficiently applied in many applications. However, some newer data-driven applications such as the Internet of Things and cloud computing call for hybrid processing approaches in order to handle the speed and accuracy required for processing such complex data. In this paper, we propose a Hybrid Distributed Batch-Stream (HDBS) architecture for anomaly detection in real-time data. The hybrid architecture, while benefiting from the accuracy provided by batch processing, also enjoys the speed and real-time features of stream processing. In the proposed architecture, our focus is on the algorithmic aspects of hybrid processing including the interaction models between batch and stream processing units, the characteristics of batch and stream machine learning algorithms and the principles of merging the results of different processing units. The driving idea of such combination is that the results of batch and stream processing units are complementary with each other, as one of them constructs accurate models based on previous data, and the other one is capable of processing new stream data in real-time. Furthermore, we propose a generalized version of the HDBS with respect to its algorithms and communication policy levels. In the generalized HDBS architecture, we address the various aspects of the interaction between the batch and stream processing units, and the merging operations to produce the final results. the evaluations of the proposed architecture using various criteria (accuracy, space complexity, and time complexity) demonstrate that the accuracy of the proposed method is higher than the accuracy of the batch processing methods, its time complexity is also similar to one of the stream processing methods and much less than the batch processing methods, which makes our proposed architecture an efficient and practical solution for real-time anomaly detection.\", \"There have been increasing demands for real time processing of the ever-growing data. In order to meet this requirement and ensure the reliable processing of streaming data, a variety of distributed stream processing architectures and platforms have been developed, which handles the fundamental task of allocating processing tasks to the currently available physical resources and routing streaming data between these resources. However, many stream processing systems lack an intelligent scheduling mechanism, in which their default schedulers allocate tasks without taking resource demands and availability, or the transfer latency between resources into consideration. Besides, stream processing has a strict request for latency. Thus it is important to give latency guarantee for distributed stream processing. In this paper, we propose two new algorithms for stream processing with latency guarantee, both the algorithms consider transfer latency and resource demand in task allocation. Both algorithms can guarantee latency constraints. Algorithm AHA reduces more than 21.3% and 58.9% resources compared with the greedy and the round-robin algorithms, and algorithm PHA further improves the resource utilization to 32.1% and 73.2%.\", \"In the era of Big Data, typical architecture of distributed real-time stream processing systems is the combination of Flume, Kafka, and Storm. As a kind of distributed message system, Kafka has the characteristics of horizontal scalability and high throughput, which is manly deployed in many areas in order to address the problem of speed mismatch between message producers and consumers. When using Kafka, we need to quickly receive data sent by producers. In addition, we need to send data to consumers quickly. Therefore, the performance of Kafka is of critical importance to the performance of the whole stream processing system. In this paper, we propose the improved design of real-time stream processing systems, and focus on improving the Kafka’s data loading process. We use Kafka cat to transfer data from the source to Kafka topic directly, which can reduce the network transmission. We also utilize the memory file system to accelerate the process of data loading, which can address the bottleneck and performance problems caused by disk I/O. Extensive experiments are conducted to evaluate the performance, which show the superiority of our improved design.\", \"In this paper, nearly 40 commonly used deep neural network(DNN) models are selected, and their cross-platform and cross-inference frameworks are deeply analysed. The main metrics of accuracy, the total number of model parameters, the computational complexity, the accuracy density, the inference time, the memory consumption and other related parameters are used to measure their performance. The heterogeneous computing experiment is implemented on both the Google Colab cloud computing platform and the Jetson Nano embedded edge computing platform. The obtained performance is compared with that of two previous computing platforms: a workstation equipped with an NVIDIA Titan X Pascal and an embedded system based on an NVIDIA Jetson TX1 board. In addition, on the Jetson Nano embedded edge computing platform, different inference frameworks are investigated to evaluate the inference efficiency of the DNN models. Regression models are established to characterize the variation in the computing performance of different DNN classification algorithms so that the inference results of unknown models can be estimated. ANOVA methods are proposed to quantify the differences between models. The experimental results have important guiding significance for the better selection, deployment and application of DNN models in practice. Codes are available at this https URL https://github.com/Foreverzfy/Model-Test.\", \"Unmanned Aerial Vehicles (UAVs), which can operate autonomously in dynamic and complex environments, are becoming increasingly common. Deep learning techniques for motion control have recently taken a major qualitative step since vision-based inference tasks can be executed directly on edge. The goal is to fully integrate the machine learning (ML) element into small UAVs. However, given the limited payload capacity and energy available on small UAVs, integrating computing resources sufficient to host ML and vehicle control functions is still challenging. This paper presents a modular and generic system that can control the UAV by evaluating vision-based ML tasks directly inside the resource-constrained UAV. Two different vision-based navigation configurations were tested and demonstrated. The first configuration implements an autonomous landing site detection system, tested with two models based on LeNet-5 and MobileNetV2, respectively. This allows the UAV to change its planned path accordingly and approach the target to land. Moreover, a model for people detection based on a custom MobileNetV2 network was evaluated in the second configuration. Finally, the execution time and power consumption were measured and compared with a cloud computing approach. The results show the ability of the developed system to dynamically react to the environment to provide the necessary maneuver after detecting the target exploiting only the constrained computational resources of the UAV controller. Furthermore, we demonstrated that moving to the edge, instead of using cloud computing inference, decreases the energy requirement of the system without reducing the quality of service.\", \"With the continuous development of Internet of Things (IoT) and the overwhelming explosion of Big Data, edge computing serves as an efficient computing mode for time stringent data processing, which can bypass the constraints of network bandwidth and delay, and has been one of the foundation of interconnected applications. Although edge computing has gradually become one of bridges between cloud computing centers and mobile terminals, the literature still lacks a thorough review on the recent advances in edge computing platforms. In this paper, we firstly introduce the definition of edge computing and advantages of edge computing platform. And then, we summarize the key technologies of constructing an edge computing platform, and propose a general framework for edge computing platform. The role of distributed storage management systems in building edge computing platform is elaborated in detail. Furthermore, we give some applications to illustrate how to use third-party edge computing platforms to build specific applications. Finally, we briefly outline current open issues of edge computing platform based on our literature survey.\"]\n",
    "        \n",
    "        # Тот же embedded-граф на случай исключения при парсинге DOCX\n",
    "        adj = {\"0\": [1, 3], \"1\": [0, 2, 4], \"2\": [1, 3, 5, 6], \"3\": [0, 2, 8], \"4\": [1, 10, 11], \"5\": [2, 8, 10], \"6\": [2, 7], \"7\": [6, 12], \"8\": [3, 5, 7, 9], \"9\": [8, 10], \"10\": [4, 5, 9, 11, 16], \"11\": [4, 10, 13], \"12\": [7, 14], \"13\": [11, 14], \"14\": [12, 13, 15], \"15\": [14, 16], \"16\": [10, 15, 17], \"17\": [16, 18], \"18\": [17, 19], \"19\": [18]}\n",
    "else:\n",
    "    # Режим embedded по умолчанию: тот же корпус/граф зашиты прямо в ноутбук\n",
    "    documents = [\"Streaming data is the data from sensors as well as other real-time surveillance systems. Distributed stream processing systems are the software that manages such data. Such frameworks have to deliver outcomes on the go instantly. They are susceptible to delay and malfunction or system failures. The system must be tolerant of faults and always accessible. Many variables, such as improved network arrival rates, node failures, and so on, disrupt the system's reliability. Some operators need to be relocated online from one physical resource to another to manage or reimburse a slow or failing node. In this study, we propose a co-location based systematic migration heuristic for live operator migration between physical resources using a migration map revised with costs for each migration. The suggested method evaluates continuous operator performance patterns and makes online scheduling decisions based on the same. The decisions include migrating operators during a node failure or straggling.\", \"Distributed stream processing engines are designed with a focus on scalability to process big data volumes in a continuous manner. We present the Theodolite method for benchmarking the scalability of distributed stream processing engines. Core of this method is the definition of use cases that microservices implementing stream processing have to fulfill. For each use case, our method identifies relevant workload dimensions that might affect the scalability of a use case. We propose to design one benchmark per use case and relevant workload dimension. We present a general benchmarking framework, which can be applied to execute the individual benchmarks for a given use case and workload dimension. Our framework executes an implementation of the use case's dataflow architecture for different workloads of the given dimension and various numbers of processing instances. This way, it identifies how resources demand evolves with increasing workloads. Within the scope of this paper, we present 4 identified use cases, derived from processing Industrial Internet of Things data, and 7 corresponding workload dimensions. We provide implementations of 4 benchmarks with Kafka Streams and Apache Flink as well as an implementation of our benchmarking framework to execute scalability benchmarks in cloud environments. We use both for evaluating the Theodolite method and for benchmarking Kafka Streams' and Flink's scalability for different deployment options.\", \"Batch and stream processing are separately and efficiently applied in many applications. However, some newer data-driven applications such as the Internet of Things and cloud computing call for hybrid processing approaches in order to handle the speed and accuracy required for processing such complex data. In this paper, we propose a Hybrid Distributed Batch-Stream (HDBS) architecture for anomaly detection in real-time data. The hybrid architecture, while benefiting from the accuracy provided by batch processing, also enjoys the speed and real-time features of stream processing. In the proposed architecture, our focus is on the algorithmic aspects of hybrid processing including the interaction models between batch and stream processing units, the characteristics of batch and stream machine learning algorithms and the principles of merging the results of different processing units. The driving idea of such combination is that the results of batch and stream processing units are complementary with each other, as one of them constructs accurate models based on previous data, and the other one is capable of processing new stream data in real-time. Furthermore, we propose a generalized version of the HDBS with respect to its algorithms and communication policy levels. In the generalized HDBS architecture, we address the various aspects of the interaction between the batch and stream processing units, and the merging operations to produce the final results. the evaluations of the proposed architecture using various criteria (accuracy, space complexity, and time complexity) demonstrate that the accuracy of the proposed method is higher than the accuracy of the batch processing methods, its time complexity is also similar to one of the stream processing methods and much less than the batch processing methods, which makes our proposed architecture an efficient and practical solution for real-time anomaly detection.\", \"There have been increasing demands for real time processing of the ever-growing data. In order to meet this requirement and ensure the reliable processing of streaming data, a variety of distributed stream processing architectures and platforms have been developed, which handles the fundamental task of allocating processing tasks to the currently available physical resources and routing streaming data between these resources. However, many stream processing systems lack an intelligent scheduling mechanism, in which their default schedulers allocate tasks without taking resource demands and availability, or the transfer latency between resources into consideration. Besides, stream processing has a strict request for latency. Thus it is important to give latency guarantee for distributed stream processing. In this paper, we propose two new algorithms for stream processing with latency guarantee, both the algorithms consider transfer latency and resource demand in task allocation. Both algorithms can guarantee latency constraints. Algorithm AHA reduces more than 21.3% and 58.9% resources compared with the greedy and the round-robin algorithms, and algorithm PHA further improves the resource utilization to 32.1% and 73.2%.\", \"In the era of Big Data, typical architecture of distributed real-time stream processing systems is the combination of Flume, Kafka, and Storm. As a kind of distributed message system, Kafka has the characteristics of horizontal scalability and high throughput, which is manly deployed in many areas in order to address the problem of speed mismatch between message producers and consumers. When using Kafka, we need to quickly receive data sent by producers. In addition, we need to send data to consumers quickly. Therefore, the performance of Kafka is of critical importance to the performance of the whole stream processing system. In this paper, we propose the improved design of real-time stream processing systems, and focus on improving the Kafka’s data loading process. We use Kafka cat to transfer data from the source to Kafka topic directly, which can reduce the network transmission. We also utilize the memory file system to accelerate the process of data loading, which can address the bottleneck and performance problems caused by disk I/O. Extensive experiments are conducted to evaluate the performance, which show the superiority of our improved design.\", \"In this paper, nearly 40 commonly used deep neural network(DNN) models are selected, and their cross-platform and cross-inference frameworks are deeply analysed. The main metrics of accuracy, the total number of model parameters, the computational complexity, the accuracy density, the inference time, the memory consumption and other related parameters are used to measure their performance. The heterogeneous computing experiment is implemented on both the Google Colab cloud computing platform and the Jetson Nano embedded edge computing platform. The obtained performance is compared with that of two previous computing platforms: a workstation equipped with an NVIDIA Titan X Pascal and an embedded system based on an NVIDIA Jetson TX1 board. In addition, on the Jetson Nano embedded edge computing platform, different inference frameworks are investigated to evaluate the inference efficiency of the DNN models. Regression models are established to characterize the variation in the computing performance of different DNN classification algorithms so that the inference results of unknown models can be estimated. ANOVA methods are proposed to quantify the differences between models. The experimental results have important guiding significance for the better selection, deployment and application of DNN models in practice. Codes are available at this https URL https://github.com/Foreverzfy/Model-Test.\", \"Unmanned Aerial Vehicles (UAVs), which can operate autonomously in dynamic and complex environments, are becoming increasingly common. Deep learning techniques for motion control have recently taken a major qualitative step since vision-based inference tasks can be executed directly on edge. The goal is to fully integrate the machine learning (ML) element into small UAVs. However, given the limited payload capacity and energy available on small UAVs, integrating computing resources sufficient to host ML and vehicle control functions is still challenging. This paper presents a modular and generic system that can control the UAV by evaluating vision-based ML tasks directly inside the resource-constrained UAV. Two different vision-based navigation configurations were tested and demonstrated. The first configuration implements an autonomous landing site detection system, tested with two models based on LeNet-5 and MobileNetV2, respectively. This allows the UAV to change its planned path accordingly and approach the target to land. Moreover, a model for people detection based on a custom MobileNetV2 network was evaluated in the second configuration. Finally, the execution time and power consumption were measured and compared with a cloud computing approach. The results show the ability of the developed system to dynamically react to the environment to provide the necessary maneuver after detecting the target exploiting only the constrained computational resources of the UAV controller. Furthermore, we demonstrated that moving to the edge, instead of using cloud computing inference, decreases the energy requirement of the system without reducing the quality of service.\", \"With the continuous development of Internet of Things (IoT) and the overwhelming explosion of Big Data, edge computing serves as an efficient computing mode for time stringent data processing, which can bypass the constraints of network bandwidth and delay, and has been one of the foundation of interconnected applications. Although edge computing has gradually become one of bridges between cloud computing centers and mobile terminals, the literature still lacks a thorough review on the recent advances in edge computing platforms. In this paper, we firstly introduce the definition of edge computing and advantages of edge computing platform. And then, we summarize the key technologies of constructing an edge computing platform, and propose a general framework for edge computing platform. The role of distributed storage management systems in building edge computing platform is elaborated in detail. Furthermore, we give some applications to illustrate how to use third-party edge computing platforms to build specific applications. Finally, we briefly outline current open issues of edge computing platform based on our literature survey.\"]\n",
    "    adj = {\"0\": [1, 3], \"1\": [0, 2, 4], \"2\": [1, 3, 5, 6], \"3\": [0, 2, 8], \"4\": [1, 10, 11], \"5\": [2, 8, 10], \"6\": [2, 7], \"7\": [6, 12], \"8\": [3, 5, 7, 9], \"9\": [8, 10], \"10\": [4, 5, 9, 11, 16], \"11\": [4, 10, 13], \"12\": [7, 14], \"13\": [11, 14], \"14\": [12, 13, 15], \"15\": [14, 16], \"16\": [10, 15, 17], \"17\": [16, 18], \"18\": [17, 19], \"19\": [18]}\n",
    "\n",
    "# Нормализуем ключи и соседей графа к int \n",
    "adj = {int(k): [int(x) for x in v] for k, v in adj.items()}\n",
    "\n",
    "# Итоговый отчёт о том, что именно выбрано и сколько элементов получено\n",
    "print(f\"Data mode: {DATA_MODE}. Documents: {len(documents)}; Nodes: {len(adj)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24ad8b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import defaultdict     # словари со значениями по умолч (после расчёта)\n",
    "\n",
    "N_DOCS = len(documents)     # размер корпуса (число документов) для расчёта IDF\n",
    "\n",
    "TOKEN_RE = re.compile(r\"[A-Za-z][A-Za-z\\-]+\")       # Токенайзер: слова на латинице, допускаем дефис и апостроф внутри слова\n",
    "\n",
    "def tokenize(text : str):\n",
    "    return [w.lower() for w in TOKEN_RE.findall(text)]      # находим все токены по шаблону и приводим к нижнему регистру"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3255da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([\"Streaming data is the data from sensors as well as other real-time surveillance systems. Distributed stream processing systems are the software that manages such data. Such frameworks have to deliver outcomes on the go instantly. They are susceptible to delay and malfunction or system failures. The system must be tolerant of faults and always accessible. Many variables, such as improved network arrival rates, node failures, and so on, disrupt the system's reliability. Some operators need to be relocated online from one physical resource to another to manage or reimburse a slow or failing node. In this study, we propose a co-location based systematic migration heuristic for live operator migration between physical resources using a migration map revised with costs for each migration. The suggested method evaluates continuous operator performance patterns and makes online scheduling decisions based on the same. The decisions include migrating operators during a node failure or straggling.\", \"Distributed stream processing engines are designed with a focus on scalability to process big data volumes in a continuous manner. We present the Theodolite method for benchmarking the scalability of distributed stream processing engines. Core of this method is the definition of use cases that microservices implementing stream processing have to fulfill. For each use case, our method identifies relevant workload dimensions that might affect the scalability of a use case. We propose to design one benchmark per use case and relevant workload dimension. We present a general benchmarking framework, which can be applied to execute the individual benchmarks for a given use case and workload dimension. Our framework executes an implementation of the use case's dataflow architecture for different workloads of the given dimension and various numbers of processing instances. This way, it identifies how resources demand evolves with increasing workloads. Within the scope of this paper, we present 4 identified use cases, derived from processing Industrial Internet of Things data, and 7 corresponding workload dimensions. We provide implementations of 4 benchmarks with Kafka Streams and Apache Flink as well as an implementation of our benchmarking framework to execute scalability benchmarks in cloud environments. We use both for evaluating the Theodolite method and for benchmarking Kafka Streams' and Flink's scalability for different deployment options.\", 'Batch and stream processing are separately and efficiently applied in many applications. However, some newer data-driven applications such as the Internet of Things and cloud computing call for hybrid processing approaches in order to handle the speed and accuracy required for processing such complex data. In this paper, we propose a Hybrid Distributed Batch-Stream (HDBS) architecture for anomaly detection in real-time data. The hybrid architecture, while benefiting from the accuracy provided by batch processing, also enjoys the speed and real-time features of stream processing. In the proposed architecture, our focus is on the algorithmic aspects of hybrid processing including the interaction models between batch and stream processing units, the characteristics of batch and stream machine learning algorithms and the principles of merging the results of different processing units. The driving idea of such combination is that the results of batch and stream processing units are complementary with each other, as one of them constructs accurate models based on previous data, and the other one is capable of processing new stream data in real-time. Furthermore, we propose a generalized version of the HDBS with respect to its algorithms and communication policy levels. In the generalized HDBS architecture, we address the various aspects of the interaction between the batch and stream processing units, and the merging operations to produce the final results. the evaluations of the proposed architecture using various criteria (accuracy, space complexity, and time complexity) demonstrate that the accuracy of the proposed method is higher than the accuracy of the batch processing methods, its time complexity is also similar to one of the stream processing methods and much less than the batch processing methods, which makes our proposed architecture an efficient and practical solution for real-time anomaly detection.', 'There have been increasing demands for real time processing of the ever-growing data. In order to meet this requirement and ensure the reliable processing of streaming data, a variety of distributed stream processing architectures and platforms have been developed, which handles the fundamental task of allocating processing tasks to the currently available physical resources and routing streaming data between these resources. However, many stream processing systems lack an intelligent scheduling mechanism, in which their default schedulers allocate tasks without taking resource demands and availability, or the transfer latency between resources into consideration. Besides, stream processing has a strict request for latency. Thus it is important to give latency guarantee for distributed stream processing. In this paper, we propose two new algorithms for stream processing with latency guarantee, both the algorithms consider transfer latency and resource demand in task allocation. Both algorithms can guarantee latency constraints. Algorithm AHA reduces more than 21.3% and 58.9% resources compared with the greedy and the round-robin algorithms, and algorithm PHA further improves the resource utilization to 32.1% and 73.2%.', 'In the era of Big Data, typical architecture of distributed real-time stream processing systems is the combination of Flume, Kafka, and Storm. As a kind of distributed message system, Kafka has the characteristics of horizontal scalability and high throughput, which is manly deployed in many areas in order to address the problem of speed mismatch between message producers and consumers. When using Kafka, we need to quickly receive data sent by producers. In addition, we need to send data to consumers quickly. Therefore, the performance of Kafka is of critical importance to the performance of the whole stream processing system. In this paper, we propose the improved design of real-time stream processing systems, and focus on improving the Kafka’s data loading process. We use Kafka cat to transfer data from the source to Kafka topic directly, which can reduce the network transmission. We also utilize the memory file system to accelerate the process of data loading, which can address the bottleneck and performance problems caused by disk I/O. Extensive experiments are conducted to evaluate the performance, which show the superiority of our improved design.', 'In this paper, nearly 40 commonly used deep neural network(DNN) models are selected, and their cross-platform and cross-inference frameworks are deeply analysed. The main metrics of accuracy, the total number of model parameters, the computational complexity, the accuracy density, the inference time, the memory consumption and other related parameters are used to measure their performance. The heterogeneous computing experiment is implemented on both the Google Colab cloud computing platform and the Jetson Nano embedded edge computing platform. The obtained performance is compared with that of two previous computing platforms: a workstation equipped with an NVIDIA Titan X Pascal and an embedded system based on an NVIDIA Jetson TX1 board. In addition, on the Jetson Nano embedded edge computing platform, different inference frameworks are investigated to evaluate the inference efficiency of the DNN models. Regression models are established to characterize the variation in the computing performance of different DNN classification algorithms so that the inference results of unknown models can be estimated. ANOVA methods are proposed to quantify the differences between models. The experimental results have important guiding significance for the better selection, deployment and application of DNN models in practice. Codes are available at this https URL https://github.com/Foreverzfy/Model-Test.', 'Unmanned Aerial Vehicles (UAVs), which can operate autonomously in dynamic and complex environments, are becoming increasingly common. Deep learning techniques for motion control have recently taken a major qualitative step since vision-based inference tasks can be executed directly on edge. The goal is to fully integrate the machine learning (ML) element into small UAVs. However, given the limited payload capacity and energy available on small UAVs, integrating computing resources sufficient to host ML and vehicle control functions is still challenging. This paper presents a modular and generic system that can control the UAV by evaluating vision-based ML tasks directly inside the resource-constrained UAV. Two different vision-based navigation configurations were tested and demonstrated. The first configuration implements an autonomous landing site detection system, tested with two models based on LeNet-5 and MobileNetV2, respectively. This allows the UAV to change its planned path accordingly and approach the target to land. Moreover, a model for people detection based on a custom MobileNetV2 network was evaluated in the second configuration. Finally, the execution time and power consumption were measured and compared with a cloud computing approach. The results show the ability of the developed system to dynamically react to the environment to provide the necessary maneuver after detecting the target exploiting only the constrained computational resources of the UAV controller. Furthermore, we demonstrated that moving to the edge, instead of using cloud computing inference, decreases the energy requirement of the system without reducing the quality of service.', 'With the continuous development of Internet of Things (IoT) and the overwhelming explosion of Big Data, edge computing serves as an efficient computing mode for time stringent data processing, which can bypass the constraints of network bandwidth and delay, and has been one of the foundation of interconnected applications. Although edge computing has gradually become one of bridges between cloud computing centers and mobile terminals, the literature still lacks a thorough review on the recent advances in edge computing platforms. In this paper, we firstly introduce the definition of edge computing and advantages of edge computing platform. And then, we summarize the key technologies of constructing an edge computing platform, and propose a general framework for edge computing platform. The role of distributed storage management systems in building edge computing platform is elaborated in detail. Furthermore, we give some applications to illustrate how to use third-party edge computing platforms to build specific applications. Finally, we briefly outline current open issues of edge computing platform based on our literature survey. 2. Алгоритм параллельного поиска в ширину (Breadth-First Search) Найти кратчайший путь от вершины 0 до вершины 19'], {0: [1, 3], 1: [0, 2, 4], 2: [1, 3, 5, 6], 3: [0, 2, 8], 4: [1, 10, 11], 5: [2, 8, 10], 6: [2, 7], 7: [6, 12], 8: [3, 5, 7, 9], 9: [8, 10], 10: [4, 5, 9, 11, 16], 11: [4, 10, 13], 12: [7, 14], 13: [11, 14], 14: [12, 13, 15], 15: [14, 16], 16: [10, 15, 17], 17: [16, 18], 18: [17, 19], 19: [18]})\n"
     ]
    }
   ],
   "source": [
    "result = parse_lab_data_from_docx(Path.joinpath(Path.cwd(), \"resources\", DOCX_PATH))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97574f7",
   "metadata": {},
   "source": [
    "## TF‑IDF — Этап 1: частоты слов в документе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34bd0dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Выполняем этап 1 TF-IDF...\n",
      "Этап 1 завершен. Получено 899 записей\n"
     ]
    }
   ],
   "source": [
    "from typing import Iterator\n",
    "\n",
    "def RECORDREADER_1():\n",
    "    for doc_id, text in enumerate(documents):\n",
    "        yield (doc_id, text)\n",
    "\n",
    "def MAP_1(key, value: str):\n",
    "    doc_id = key\n",
    "    toks = tokenize(value)\n",
    "    for tok in toks:\n",
    "        yield ((doc_id, tok), 1)\n",
    "    # Подсчёт total токенов на документ\n",
    "    yield ((doc_id, \"*CNT*\"), len(toks))\n",
    "\n",
    "def REDUCE_1(key, values: Iterator[int]):\n",
    "    s = 0\n",
    "    for v in values:\n",
    "        s += v\n",
    "    yield (key, s)\n",
    "\n",
    "print(\"Выполняем этап 1 TF-IDF...\")\n",
    "stage1_out = list(MapReduce(RECORDREADER_1, MAP_1, REDUCE_1))\n",
    "print(f\"Этап 1 завершен. Получено {len(stage1_out)} записей\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113e1888",
   "metadata": {},
   "source": [
    "## TF‑IDF — Этап 2: в скольких документах встречается слово (DF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b030e1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Выполняем этап 2 TF-IDF...\n",
      "Этап 2 завершен. Получено 899 записей\n"
     ]
    }
   ],
   "source": [
    "def RECORDREADER_2():\n",
    "    for kv in stage1_out:\n",
    "        yield kv\n",
    "\n",
    "def MAP_2(key, value):\n",
    "    # key == (doc_id, tok) OR (doc_id, \"*CNT*\")\n",
    "    doc_id, tok = key\n",
    "    if tok == \"*CNT*\":\n",
    "        yield ((\"TOTAL\", doc_id), value)\n",
    "    else:\n",
    "        # отмечаем факт присутствия терма в документе\n",
    "        yield ((tok, doc_id), 1)\n",
    "\n",
    "def REDUCE_2(key, values: Iterator[int]):\n",
    "    if key[0] == \"TOTAL\":\n",
    "        total = 0\n",
    "        for v in values:\n",
    "            total += v\n",
    "        yield (key, total)\n",
    "    else:\n",
    "        tok, doc_id = key\n",
    "        cnt = 0\n",
    "        for v in values:\n",
    "            cnt += v\n",
    "        if cnt > 0:\n",
    "            yield ((\"DF\", tok), doc_id)\n",
    "\n",
    "print(\"Выполняем этап 2 TF-IDF...\")\n",
    "stage2_out = list(MapReduce(RECORDREADER_2, MAP_2, REDUCE_2))\n",
    "print(f\"Этап 2 завершен. Получено {len(stage2_out)} записей\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8676ce",
   "metadata": {},
   "source": [
    "## TF‑IDF — Этап 3: расчёт TF‑IDF и топ‑5 слов на документ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "207fd387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Выполняем этап 3 TF-IDF...\n",
      "\n",
      "Результаты TF-IDF - топ-5 слов для каждого документа:\n",
      "Документ 0: [('migration', 0.028486), ('node', 0.021364), ('or', 0.01899), ('such', 0.014243), ('failures', 0.014243)]\n",
      "Документ 1: [('case', 0.025114), ('benchmarking', 0.020091), ('workload', 0.020091), ('use', 0.018953), ('scalability', 0.016743)]\n",
      "Документ 2: [('batch', 0.029083), ('hybrid', 0.014542), ('units', 0.014542), ('accuracy', 0.012118), ('hdbs', 0.010906)]\n",
      "Документ 3: [('latency', 0.037133), ('guarantee', 0.018566), ('demands', 0.012378), ('task', 0.012378), ('resource', 0.012378)]\n",
      "Документ 4: [('kafka', 0.02666), ('message', 0.011426), ('producers', 0.011426), ('consumers', 0.011426), ('quickly', 0.011426)]\n",
      "Документ 5: [('dnn', 0.020794), ('jetson', 0.015596), ('embedded', 0.015596), ('models', 0.014712), ('inference', 0.013863)]\n",
      "Документ 6: [('uav', 0.017474), ('uavs', 0.013106), ('control', 0.013106), ('vision-based', 0.013106), ('ml', 0.013106)]\n",
      "Документ 7: [('edge', 0.029366), ('computing', 0.024903), ('platform', 0.020753), ('literature', 0.012452), ('applications', 0.012452)]\n"
     ]
    }
   ],
   "source": [
    "def RECORDREADER_3():\n",
    "    for kv in stage1_out:\n",
    "        yield kv\n",
    "    for kv in stage2_out:\n",
    "        yield kv\n",
    "\n",
    "def MAP_3(key, value):\n",
    "    # stage1: ((doc, tok), cnt) | ((doc, \"*CNT*\"), total)\n",
    "    # stage2: ((\"TOTAL\", doc), total) | ((\"DF\", tok), doc_id)\n",
    "    if isinstance(key, tuple) and len(key) == 2 and isinstance(key[0], int):\n",
    "        doc_id, tok = key\n",
    "        if tok == \"*CNT*\":\n",
    "            yield ((\"TOTAL\", doc_id), value)\n",
    "        else:\n",
    "            yield ((\"TF\", doc_id, tok), (\"CNT\", value))\n",
    "    elif key[0] == \"TOTAL\":\n",
    "        _, doc_id = key\n",
    "        yield ((\"TOTAL\", doc_id), value)\n",
    "    elif key[0] == \"DF\":\n",
    "        _, tok = key\n",
    "        yield ((\"DFTOK\", tok), value)\n",
    "\n",
    "\n",
    "def REDUCE_3(group_key, values: Iterator):\n",
    "    if group_key[0] == \"TOTAL\":\n",
    "        total = 0\n",
    "        for v in values:\n",
    "            total += v\n",
    "        yield (group_key, total)\n",
    "    elif group_key[0] == \"DFTOK\":\n",
    "        seen = set(values)\n",
    "        df = len(seen)\n",
    "        yield ((\"DF\", group_key[1]), df)\n",
    "    elif group_key[0] == \"TF\":\n",
    "        cnt = 0\n",
    "        for tag, v in values:\n",
    "            if tag == \"CNT\":\n",
    "                cnt += v\n",
    "        yield (group_key, cnt)\n",
    "\n",
    "print(\"Выполняем этап 3 TF-IDF...\")\n",
    "stage3_intermediate = list(MapReduce(RECORDREADER_3, MAP_3, REDUCE_3))\n",
    "\n",
    "# Собираем TOTAL, DF, TF и считаем tf-idf\n",
    "totals, dfs, tfs_raw = {}, {}, {}\n",
    "for key, val in stage3_intermediate:\n",
    "    if key[0] == \"TOTAL\":\n",
    "        totals[key[1]] = val\n",
    "    elif key[0] == \"DF\":\n",
    "        dfs[key[1]] = val\n",
    "    elif key[0] == \"TF\":\n",
    "        _, doc_id, tok = key\n",
    "        tfs_raw[(doc_id, tok)] = val\n",
    "\n",
    "tfidf = defaultdict(dict)\n",
    "for (doc_id, tok), tn in tfs_raw.items():\n",
    "    cn = totals.get(doc_id, 1)\n",
    "    tf = tn / cn if cn else 0.0\n",
    "    df = dfs.get(tok, 1)\n",
    "    idf = math.log(N_DOCS / df) if df > 0 else 0.0\n",
    "    tfidf[doc_id][tok] = tf * idf\n",
    "\n",
    "# Выводим топ-5 слов для каждого документа\n",
    "print(\"\\nРезультаты TF-IDF - топ-5 слов для каждого документа:\")\n",
    "top5_per_doc = {doc_id: sorted(scores.items(), key=lambda kv: kv[1], reverse=True)[:5]\n",
    "                for doc_id, scores in tfidf.items()}\n",
    "\n",
    "for doc_id, pairs in sorted(top5_per_doc.items()):\n",
    "    print(f\"Документ {doc_id}: {[(w, round(s,6)) for w,s in pairs]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0439dee4",
   "metadata": {},
   "source": [
    "## Поиск кратчайшего пути на графе с использованием алгоритма BFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8bfc063a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BFS -> iters: 7 distance: 7 path: [0, 1, 4, 10, 16, 17, 18, 19]\n"
     ]
    }
   ],
   "source": [
    "SRC, DST = 0, 19\n",
    "\n",
    "def initial_graph():\n",
    "    for n in sorted(adj.keys()):\n",
    "        yield (n, {\"adj\": adj[n], \"dist\": (0 if n==SRC else float(\"inf\")), \"prev\": (None if n!=SRC else -1)})\n",
    "\n",
    "current_state = list(initial_graph())\n",
    "\n",
    "def RECORDREADER_BFS():\n",
    "    for kv in current_state:\n",
    "        yield kv\n",
    "\n",
    "def MAP_BFS(node_id, node_state):\n",
    "    yield (node_id, (\"NODE\", node_state))\n",
    "    d = node_state[\"dist\"]\n",
    "    if d < float(\"inf\"):\n",
    "        for nb in node_state[\"adj\"]:\n",
    "            yield (nb, (\"DIST\", d+1, node_id))\n",
    "\n",
    "def REDUCE_BFS(node_id, values):\n",
    "    best = {\"adj\": [], \"dist\": float(\"inf\"), \"prev\": None}\n",
    "    proposals = []\n",
    "    for tag, *rest in values:\n",
    "        if tag == \"NODE\":\n",
    "            best = rest[0]\n",
    "        elif tag == \"DIST\":\n",
    "            proposals.append(tuple(rest))\n",
    "    best_dist = best[\"dist\"]; best_prev = best[\"prev\"]\n",
    "    for d, prev in proposals:\n",
    "        if d < best_dist:\n",
    "            best_dist, best_prev = d, prev\n",
    "    out = {\"adj\": best[\"adj\"], \"dist\": best_dist, \"prev\": best_prev}\n",
    "    yield (node_id, out)\n",
    "\n",
    "def should_stop(prev_state, new_state, target_reached: bool) -> bool:\n",
    "    \"\"\"Возвращает True, если нужно завершить итерации.\"\"\"\n",
    "    if target_reached:\n",
    "        return True\n",
    "    if len(prev_state) != len(new_state):\n",
    "        return False\n",
    "    for i in range(len(new_state)):\n",
    "        if prev_state[i][1][\"dist\"] != new_state[i][1][\"dist\"] or prev_state[i][1][\"prev\"] != new_state[i][1][\"prev\"]:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def run_bfs(max_iters=200):\n",
    "    global current_state\n",
    "    iters = 0\n",
    "    while True:\n",
    "        iters += 1\n",
    "        prev_state = current_state\n",
    "        new_state = list(MapReduce(RECORDREADER_BFS, MAP_BFS, REDUCE_BFS))\n",
    "        current_state = new_state\n",
    "        target_rec = dict(current_state).get(DST, {\"dist\": float(\"inf\")})\n",
    "        if should_stop(prev_state, new_state, target_rec[\"dist\"] < float(\"inf\")) or iters >= max_iters:\n",
    "            return iters, target_rec\n",
    "\n",
    "iters, target_rec = run_bfs()\n",
    "state_map = dict(current_state)\n",
    "path = []\n",
    "if target_rec[\"dist\"] < float(\"inf\"):\n",
    "    node = DST\n",
    "    while node is not None and node != -1:\n",
    "        path.append(node)\n",
    "        node = state_map[node][\"prev\"]\n",
    "    path.reverse()\n",
    "\n",
    "print(\"BFS -> iters:\", iters, \"distance:\", target_rec[\"dist\"], \"path:\", path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
